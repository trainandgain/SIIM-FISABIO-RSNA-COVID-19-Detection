{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prepared-abuse",
   "metadata": {},
   "source": [
    "# Logging\n",
    "\n",
    "Implementing my own custom logger.\n",
    "\n",
    "Json data should save as follows:\n",
    "\n",
    "<code>{'type': hyper, 'model':?, 'optim': ?, 'model': ?, 'train_len': ?, 'val_len': ?, 'device': ? ...etc...}</code>\n",
    "\n",
    "<code>{'type': train, 'epoch': num, 'batch': num, 'loss': num, ...etc...}</code>\n",
    "\n",
    "<code>{'type': val, 'epoch': num, 'batch': num, 'loss': num, 'metric': num ...etc...}</code>\n",
    "\n",
    "<code>{'type': final, 'epochs': num, 'batches': num, 'final_loss': num, 'final_metric': num ...etc...}</code>\n",
    "\n",
    "Then the logger will save to a json file with four possible types. The output json file will be of structure:\n",
    "\n",
    "<code>{'model: ?, 'hyper_params': ...etc..., 'data':{\n",
    "    {'type': train, 'epoch': num, 'batch': num, 'loss': num, ...etc...}\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    {'type': val, 'epoch': num, 'batch': num, 'loss': num, 'metric': num ...etc...}\n",
    "    },\n",
    "    'num_epochs: num, 'num_batches': num, 'final_loss': num, 'final_metric': num,\n",
    "}</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "annoying-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "preliminary-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logman(object):\n",
    "    \"\"\"\n",
    "    Json data should save as follows:\n",
    "    \n",
    "    {'type': hyper, 'model':?, 'optim': ?, 'model': ?, 'train_len': ?, 'val_len': ?, 'device': ? ...etc...}\n",
    "\n",
    "    {'type': train, 'epoch': num, 'batch': num, 'loss': num, ...etc...}\n",
    "\n",
    "    {'type': val, 'epoch': num, 'batch': num, 'loss': num, 'metric': num ...etc...}\n",
    "\n",
    "    {'type': final, 'epochs': num, 'batches': num, 'final_loss': num, 'final_metric': num ...etc...}\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, hyper, save_path='./', save_name='logs'):\n",
    "        #load\n",
    "        self.hyper = hyper\n",
    "        self.save_path = save_path\n",
    "        self.save_name = save_name\n",
    "        # assertions\n",
    "        assert self.hyper['type'] == 'hyper'\n",
    "        assert self.hyper['model']\n",
    "        # init store\n",
    "        self.store = {'model': self.hyper['model']}\n",
    "        self.store.update({k: v for k, v in self.hyper.items() if (k != 'type' and k != 'model')})\n",
    "        self.store['data'] = []\n",
    "        # save empty logs\n",
    "        self.save_logs()\n",
    "        \n",
    "    def save_logs(self):\n",
    "        \"\"\"\n",
    "        The current implementation does not append or concatenate current file\n",
    "        but instead save on top of current file with large dictionary.\n",
    "        \"\"\"\n",
    "        with open(os.path.join(self.save_path, self.save_name)+'.json','w') as file:\n",
    "            json.dump(self.store, file, indent = 4)\n",
    "            file.close()\n",
    "            \n",
    "    def log(self, data):\n",
    "        \"\"\"\n",
    "        Takes in any input data of form dict.\n",
    "        Handles data by key 'type'.\n",
    "        Sends to relevant method.\n",
    "        \"\"\"\n",
    "        if data:\n",
    "            # first log\n",
    "            if not self.store['data']:\n",
    "                self.store['data'] = [data]\n",
    "            else:\n",
    "                # check for final\n",
    "                if data['type'] == 'final':\n",
    "                    self.finalise(data)\n",
    "                else:\n",
    "                    # append data to data key in store\n",
    "                    self.store['data'].append(data)\n",
    "        else:\n",
    "            # error\n",
    "            self.store['data'].append({'type': 'error', 'reason': 'No data present'})\n",
    "    \n",
    "    def finalise(self, data):\n",
    "        \"\"\"\n",
    "        Finalise logs, send final parameters to dict.\n",
    "        Save logs\n",
    "        \"\"\"\n",
    "        self.store.update({k: v for k, v in data.items() if (k != 'type' and k != 'model')})\n",
    "        self.save_logs()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dutch-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_hyper = {'type': 'hyper', 'model': 1, 'optim': 2, 'model': 3, 'train_len': 4, 'val_len': 5, 'device': 6}\n",
    "test_train = {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3}\n",
    "test_val = {'type': 'val', 'epoch': 1, 'batch': 2, 'loss': 3, 'metric': 4}\n",
    "test_final = {'type': 'final', 'epochs': 1, 'batches': 2, 'final_loss': 3, 'final_metric': 4}\n",
    "save_path = './'\n",
    "save_name = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "threaded-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "logman = logman(test_hyper, save_path, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "appreciated-tribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 3, 'optim': 2, 'train_len': 4, 'val_len': 5, 'device': 6, 'data': []}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logman.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "nearby-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    logman.log(test_train)\n",
    "    \n",
    "for i in range(5):\n",
    "    logman.log(test_val)\n",
    "    \n",
    "logman.log(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "racial-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 3,\n",
       " 'optim': 2,\n",
       " 'train_len': 4,\n",
       " 'val_len': 5,\n",
       " 'device': 6,\n",
       " 'data': [{'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'train', 'epoch': 1, 'batch': 2, 'loss': 3},\n",
       "  {'type': 'val', 'epoch': 1, 'batch': 2, 'loss': 3, 'metric': 4},\n",
       "  {'type': 'val', 'epoch': 1, 'batch': 2, 'loss': 3, 'metric': 4},\n",
       "  {'type': 'val', 'epoch': 1, 'batch': 2, 'loss': 3, 'metric': 4},\n",
       "  {'type': 'val', 'epoch': 1, 'batch': 2, 'loss': 3, 'metric': 4},\n",
       "  {'type': 'val', 'epoch': 1, 'batch': 2, 'loss': 3, 'metric': 4}],\n",
       " 'epochs': 1,\n",
       " 'batches': 2,\n",
       " 'final_loss': 3,\n",
       " 'final_metric': 4}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logman.store"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell]",
   "language": "python",
   "name": "conda-env-cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
