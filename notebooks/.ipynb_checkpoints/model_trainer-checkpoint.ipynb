{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671c63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import platform\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# vis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "from math import ceil\n",
    "import cv2\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adff9c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "train = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed791c10",
   "metadata": {},
   "source": [
    "## Generate Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c40478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 6334/6334 [00:00<00:00, 9896.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>OpacityCount</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2_image</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\Admin\\Git\\SIIM\\train\\5776db0cec75\\814...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\Admin\\Git\\SIIM\\train\\ff0879eb20ed\\d8a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc_image</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\Admin\\Git\\SIIM\\train\\9d514ce429a7\\228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f_image</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\Admin\\Git\\SIIM\\train\\28dddc8559b2\\4d4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891_image</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\Admin\\Git\\SIIM\\train\\dfd9fdd85a3e\\491...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              boxes  \\\n",
       "0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f_image                                                NaN   \n",
       "2  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3  001398f4ff4f_image  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4  001bd15d1891_image  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "   Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                       0                   1                         0   \n",
       "1                       1                   0                         0   \n",
       "2                       0                   1                         0   \n",
       "3                       0                   0                         0   \n",
       "4                       0                   1                         0   \n",
       "\n",
       "   Atypical Appearance  OpacityCount  \\\n",
       "0                    0             2   \n",
       "1                    0             0   \n",
       "2                    0             2   \n",
       "3                    1             1   \n",
       "4                    0             2   \n",
       "\n",
       "                                                path  \n",
       "0  C:\\Users\\Admin\\Git\\SIIM\\train\\5776db0cec75\\814...  \n",
       "1  C:\\Users\\Admin\\Git\\SIIM\\train\\ff0879eb20ed\\d8a...  \n",
       "2  C:\\Users\\Admin\\Git\\SIIM\\train\\9d514ce429a7\\228...  \n",
       "3  C:\\Users\\Admin\\Git\\SIIM\\train\\28dddc8559b2\\4d4...  \n",
       "4  C:\\Users\\Admin\\Git\\SIIM\\train\\dfd9fdd85a3e\\491...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train directory\n",
    "TRAIN_DIR = \"C:\\\\Users\\\\Admin\\\\Git\\\\SIIM\\\\train\\\\\"\n",
    "# paths\n",
    "paths = list()\n",
    "# create path column\n",
    "for _id in tqdm(train['StudyInstanceUID']):\n",
    "    try:\n",
    "        paths.append(glob.glob(os.path.join(TRAIN_DIR, _id +\"/*/*\"))[0])\n",
    "    except:\n",
    "        paths.append('')\n",
    "train['path'] = paths\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prescription-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove where paths not found\n",
    "train = train[train.path != ''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "former-alexandria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>OpacityCount</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, boxes, label, StudyInstanceUID, Negative for Pneumonia, Typical Appearance, Indeterminate Appearance, Atypical Appearance, OpacityCount, path]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train[train.path == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7a2f0",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a41bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_pcent = 0.8\n",
    "    TRAIN_BS = 4\n",
    "    VALID_BS = 4\n",
    "    NB_EPOCHS = 4\n",
    "    model_name = 'EfficientNETB2'\n",
    "    reshape_size = (400, 400)\n",
    "    num_classes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9e544",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a7d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIIM(Dataset):\n",
    "    def __init__(self, df, is_train=True, augments=None, \n",
    "                 reshape_size=Config.reshape_size):\n",
    "        super().__init__()\n",
    "        # random sample data\n",
    "        self.df = df.sample(frac=1).reset_index(drop=True)\n",
    "        # training or validation\n",
    "        self.is_train = is_train\n",
    "        # augmentations\n",
    "        self.augments = augments\n",
    "        self.reshape_size = reshape_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def dicom2array(path, voi_lut=True, fix_monochrome=True):\n",
    "        dicom = pydicom.read_file(path)\n",
    "        # VOI LUT (if available by DICOM device) is used to\n",
    "        # transform raw DICOM data to \"human-friendly\" view\n",
    "        if voi_lut:\n",
    "            data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "        else:\n",
    "            data = dicom.pixel_array\n",
    "        # depending on this value, X-ray may look inverted - fix that:\n",
    "        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            data = np.amax(data) - data\n",
    "        data = data - np.min(data)\n",
    "        data = data / np.max(data)\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # retrieve image\n",
    "        image_id = self.df['StudyInstanceUID'].values[idx]\n",
    "        image_path = self.df['path'].values[idx]\n",
    "        # get image\n",
    "        image = self.dicom2array(image_path)\n",
    "        # recolour\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        # resize\n",
    "        image = cv2.resize(image, self.reshape_size)\n",
    "        # Augments\n",
    "        if self.augments:\n",
    "            image = self.augments(image=image)\n",
    "        else:\n",
    "            image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "            image = torch.tensor(image)  \n",
    "            \n",
    "        # if train\n",
    "        if self.is_train:\n",
    "            label = self.df[self.df['StudyInstanceUID'] == image_id].values.tolist()[0][4:-2]\n",
    "            return image, torch.tensor(label)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c1f70",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Fake model function that should output a value of 1 for either:\n",
    "\n",
    "<code>'negative', 'typical', 'indeterminate', 'atypical'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb55fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(NN, self).__init__()\n",
    "        # model spec\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.convolutions = nn.Sequential(nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "                                          *(list(resnet18().children())[1:-1]))\n",
    "        self.dense = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # batch size\n",
    "        batch_size = X.shape[0]\n",
    "        # create fake data\n",
    "        rand = torch.randn([batch_size, 4])\n",
    "        return Variable(self.out(rand), requires_grad=True)\n",
    "    \n",
    "    \n",
    "class EfficientNETB2(nn.Module):\n",
    "    def __init__(self, NUM_CLASSES=Config.num_classes, pretrained=True):\n",
    "        super(EfficientNETB2, self).__init__()\n",
    "        # model\n",
    "        self.NUM_CLASSES = NUM_CLASSES\n",
    "        self.effnet = self.load_effnet(pretrained)\n",
    "        self.effnet._fc = nn.Linear(1408, self.NUM_CLASSES)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "    def load_effnet(self, pretrained):\n",
    "        if pretrained == True:\n",
    "            effnet = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "        else:\n",
    "            effnet = EfficientNet.from_name(\"efficientnet-b2\")\n",
    "        return effnet\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.effnet(X)\n",
    "        output = self.out(X)\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f038ff59",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf2b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, train_dataloader, valid_dataloader, model,\n",
    "                optimiser, loss_fn, val_loss_fn, device='cpu'):\n",
    "        \"\"\"\n",
    "        Constructor for Trainer class\n",
    "        \"\"\"\n",
    "        self.train = train_dataloader\n",
    "        self.valid = valid_dataloader\n",
    "        self.model = model\n",
    "        self.optim = optimiser\n",
    "        self.loss_fn = loss_fn\n",
    "        self.val_loss_fn = val_loss_fn\n",
    "        self.device = device\n",
    "        \n",
    "    def train_one_cycle(self):\n",
    "        \"\"\"\n",
    "        Run one epoch of training, backpropogation and optimisation.\n",
    "        \"\"\"\n",
    "            \n",
    "        # model train mode\n",
    "        model.train()\n",
    "        \n",
    "        # progress bar\n",
    "        train_prog_bar = tqdm(self.train, total=len(self.train))\n",
    "        \n",
    "        # stats\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "        running_loss = 0\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            for xtrain, ytrain in train_prog_bar:\n",
    "                # send to devices\n",
    "                xtrain = xtrain.to(self.device).float()\n",
    "                ytrain = ytrain.to(self.device).float()\n",
    "                \n",
    "                # get predictions\n",
    "                pred = model(xtrain)\n",
    "                # training\n",
    "                train_loss = self.loss_fn(pred, ytrain)\n",
    "\n",
    "                # Backpropogation\n",
    "                \n",
    "                self.optim.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optim.step()\n",
    "                \n",
    "                # For averaging and reporting later\n",
    "                running_loss += train_loss.item()\n",
    "                \n",
    "                # convert predictions to numpy\n",
    "                train_predictions = torch.argmax(pred, 1).detach().cpu().numpy()\n",
    "                train_labels = ytrain.detach().cpu().numpy()\n",
    "                \n",
    "                # append to stats\n",
    "                all_train_preds += [train_predictions]\n",
    "                all_train_labels += [train_labels]\n",
    "\n",
    "                # show the current loss to the progress bar\n",
    "                train_pbar_desc = f'loss: {train_loss.item():.4f}'\n",
    "                train_prog_bar.set_description(desc=train_pbar_desc)\n",
    "                \n",
    "            # average the running loss over all batches and return\n",
    "            train_running_loss = running_loss / len(self.train)\n",
    "            print(f\"Final Training Loss: {train_running_loss:.4f}\")\n",
    "\n",
    "            # free memory\n",
    "            del all_train_labels, all_train_preds, train_predictions, train_labels, xtrain, ytrain, pred\n",
    "            # free up cache\n",
    "            torch.cuda.empty_cache()\n",
    "                \n",
    "            return(train_running_loss)\n",
    "        \n",
    "\n",
    "    def valid_one_cycle(self):\n",
    "        \"\"\"\n",
    "        Runs one epoch of prediction\n",
    "        \"\"\"        \n",
    "        model.eval()\n",
    "        \n",
    "        valid_prog_bar = tqdm(self.valid, total=len(self.valid))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            all_valid_labels = []\n",
    "            all_valid_preds = []\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            for xval, yval in valid_prog_bar:\n",
    "                xval = xval.to(self.device).float()\n",
    "                yval = yval.to(self.device).float()\n",
    "                \n",
    "                val_z = model(xval)\n",
    "                \n",
    "                val_loss = self.val_loss_fn(val_z, yval)\n",
    "                \n",
    "                running_loss += val_loss.item()\n",
    "                \n",
    "                val_pred = torch.argmax(val_z, 1).detach().cpu().numpy()\n",
    "                val_label = yval.detach().cpu().numpy()\n",
    "                \n",
    "                all_valid_labels += [val_label]\n",
    "                all_valid_preds += [val_pred]\n",
    "            \n",
    "                # Show the current loss\n",
    "                valid_pbar_desc = f\"loss: {val_loss.item():.4f}\"\n",
    "                valid_prog_bar.set_description(desc=valid_pbar_desc)\n",
    "            \n",
    "            # Get the final loss\n",
    "            final_loss_val = running_loss / len(self.valid)\n",
    "            \n",
    "            # Get Validation Accuracy\n",
    "            all_valid_labels = np.concatenate(all_valid_labels)\n",
    "            all_valid_preds = np.concatenate(all_valid_preds)\n",
    "            \n",
    "            print(f\"Final Validation Loss: {final_loss_val:.4f}\")\n",
    "            \n",
    "            # Free up memory\n",
    "            del all_valid_labels, all_valid_preds, val_label, val_pred, xval, yval, val_z\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return (final_loss_val, model)    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f9d19",
   "metadata": {},
   "source": [
    "# Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac98bb7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training on 4873 samples (80%) and validation on 1219 (20%) samples\n",
      "[INFO] Using GPU: GeForce GTX 970\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                       | 0/1219 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model: EfficientNETB2\n",
      "-------------------- EPOCH: 1/4 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.2872:  16%|███████▎                                       | 189/1219 [04:05<36:42,  2.14s/it]C:\\Users\\Admin\\miniconda3\\envs\\cell\\lib\\site-packages\\pydicom\\pixel_data_handlers\\numpy_handler.py:341: UserWarning: The length of the pixel data in the dataset (13262360 bytes) indicates it contains excess padding. 216296 bytes will be removed from the end of the data\n",
      "  warnings.warn(msg)\n",
      "loss: 0.2673: 100%|██████████████████████████████████████████████| 1219/1219 [26:35<00:00,  1.31s/it]\n",
      "  0%|                                                                        | 0/305 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 0.4460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1028: 100%|████████████████████████████████████████████████| 305/305 [05:02<00:00,  1.01it/s]\n",
      "  0%|                                                                       | 0/1219 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Loss: 0.4256\n",
      "-------------------- EPOCH: 2/4 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.2351: 100%|██████████████████████████████████████████████| 1219/1219 [26:40<00:00,  1.31s/it]\n",
      "  0%|                                                                        | 0/305 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 0.4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0335: 100%|████████████████████████████████████████████████| 305/305 [04:58<00:00,  1.02it/s]\n",
      "  0%|                                                                       | 0/1219 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Loss: 0.4280\n",
      "-------------------- EPOCH: 3/4 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1788: 100%|██████████████████████████████████████████████| 1219/1219 [26:41<00:00,  1.31s/it]\n",
      "  0%|                                                                        | 0/305 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 0.3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0554: 100%|████████████████████████████████████████████████| 305/305 [04:57<00:00,  1.03it/s]\n",
      "  0%|                                                                       | 0/1219 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Loss: 0.4366\n",
      "-------------------- EPOCH: 4/4 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1912: 100%|██████████████████████████████████████████████| 1219/1219 [26:41<00:00,  1.31s/it]\n",
      "  0%|                                                                        | 0/305 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 0.3758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1264: 100%|████████████████████████████████████████████████| 305/305 [04:57<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Loss: 0.4107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Cycle\n",
    "nb_training_samples = int(Config.train_pcent * train.id.shape[0])\n",
    "train_data = train[:nb_training_samples]\n",
    "valid_data = train[nb_training_samples:]\n",
    "\n",
    "print(f\"[INFO] Training on {train_data.shape[0]} samples ({int(Config.train_pcent*100)}%) and validation on {valid_data.shape[0]} ({ceil(abs(1 - Config.train_pcent) * 100)}%) samples\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "        DEVICE = torch.device('cuda:0')\n",
    "else:\n",
    "    print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n",
    "    DEVICE = torch.device('cpu')\n",
    "        \n",
    "\n",
    "# Make Training and Validation Datasets\n",
    "training_set = SIIM(\n",
    "    df=train_data\n",
    ")\n",
    "\n",
    "validation_set = SIIM(\n",
    "    df=valid_data\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    training_set,\n",
    "    batch_size=Config.TRAIN_BS,\n",
    "    shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    validation_set,\n",
    "    batch_size=Config.VALID_BS,\n",
    "    shuffle=False)\n",
    "\n",
    "if \"EfficientNETB2\" in Config.model_name in Config.model_name:        \n",
    "    model = EfficientNETB2().to(DEVICE)\n",
    "    \n",
    "else:\n",
    "    raise RuntimeError(\"Must specify a valid model type to train.\")\n",
    "\n",
    "print(f\"Training Model: {Config.model_name}\")\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "loss_fn_train = nn.BCELoss()\n",
    "loss_fn_val = nn.BCELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    train_dataloader=train_loader,\n",
    "    valid_dataloader=valid_loader,\n",
    "    model=model,\n",
    "    optimiser=optim,\n",
    "    loss_fn=loss_fn_train,\n",
    "    val_loss_fn=loss_fn_val,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "train_losses_eff = []\n",
    "valid_losses_eff = []\n",
    "\n",
    "for epoch in range(Config.NB_EPOCHS):\n",
    "    # Empty CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"{'-'*20} EPOCH: {epoch+1}/{Config.NB_EPOCHS} {'-'*20}\")\n",
    "\n",
    "    # Run one training epoch\n",
    "    current_train_loss = trainer.train_one_cycle()\n",
    "    train_losses_eff.append(current_train_loss)\n",
    "\n",
    "    # Run one validation epoch\n",
    "    current_val_loss, op_model = trainer.valid_one_cycle()\n",
    "    valid_losses_eff.append(current_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-mitchell",
   "metadata": {},
   "source": [
    "# Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "noted-walnut",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.plot(np.arange(0, len(train_losses_eff), 1), train_losses_eff, label='Train')\n",
    "plt.plot(np.arange(0, len(valid_losses_eff), 1), valid_losses_eff, label='Valid')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('# of epochs')\n",
    "plt.title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "offshore-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(op_model, 'C:\\\\Users\\\\Admin\\\\Git\\\\SIIM\\\\models\\\\EfficientNETB2-4\\\\model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell]",
   "language": "python",
   "name": "conda-env-cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
