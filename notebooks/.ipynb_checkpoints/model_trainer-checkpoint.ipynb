{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671c63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import platform\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# vis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adff9c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "train = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a41bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_pcent = 0.8\n",
    "    TRAIN_BS = 32\n",
    "    VALID_BS = 16\n",
    "    NB_EPOCHS = 1\n",
    "    model_name = 'NN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9e544",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a7d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIIM(Dataset):\n",
    "    def __init__(self, df, is_train=True, augments=None):\n",
    "        super().__init__()\n",
    "        # random sample data\n",
    "        self.df = df.sample(frac=1).reset_index(drop=True)\n",
    "        # training or validation\n",
    "        self.is_train = is_train\n",
    "        # augmentations\n",
    "        self.augments = augments\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_image(image_path):\n",
    "        return([1])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # retrieve image\n",
    "        image_id = self.df['StudyInstanceUID'].values[idx]\n",
    "        image_path = '' # self.df['path'].values[idx]\n",
    "        # get image (obviously change in real implementation)\n",
    "        image = self.get_image(image_path)\n",
    "        \n",
    "        # Augments\n",
    "        if self.augments:\n",
    "            image = self.augments(image=image)\n",
    "        else:\n",
    "            image = torch.tensor(image)\n",
    "            \n",
    "        # if train\n",
    "        if self.is_train:\n",
    "            label = self.df[self.df['StudyInstanceUID'] == image_id].values.tolist()[0][4:-1]\n",
    "            return image, torch.tensor(label)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.df.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c1f70",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Fake model function that should output a value of 1 for either:\n",
    "\n",
    "<code>'negative', 'typical', 'indeterminate', 'atypical'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb55fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(NN, self).__init__()\n",
    "        # model spec\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.convolutions = nn.Sequential(nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "                                          *(list(resnet18().children())[1:-1]))\n",
    "        self.dense = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # batch size\n",
    "        batch_size = X.shape[0]\n",
    "        # create fake data\n",
    "        rand = torch.randn([batch_size, 4])\n",
    "        return Variable(self.out(rand), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f038ff59",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abf2b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, train_dataloader, valid_dataloader, model,\n",
    "                optimiser, loss_fn, val_loss_fn, device='cpu'):\n",
    "        \"\"\"\n",
    "        Constructor for Trainer class\n",
    "        \"\"\"\n",
    "        self.train = train_dataloader\n",
    "        self.valid = valid_dataloader\n",
    "        self.model = model\n",
    "        self.optim = optimiser\n",
    "        self.loss_fn = loss_fn\n",
    "        self.val_loss_fn = val_loss_fn\n",
    "        self.device = device\n",
    "        \n",
    "    def train_one_cycle(self):\n",
    "        \"\"\"\n",
    "        Run one epoch of training, backpropogation and optimisation.\n",
    "        \"\"\"\n",
    "            \n",
    "        # model train mode\n",
    "        model.train()\n",
    "        \n",
    "        # progress bar\n",
    "        train_prog_bar = tqdm(self.train, total=len(self.train))\n",
    "        \n",
    "        # stats\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "        running_loss = 0\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            for xtrain, ytrain in self.train:\n",
    "                # send to devices\n",
    "                xtrain = xtrain.to(self.device).float()\n",
    "                ytrain = ytrain.to(self.device).float()\n",
    "                \n",
    "                # get predictions\n",
    "                pred = model(xtrain)\n",
    "                # training\n",
    "                train_loss = self.loss_fn(pred, ytrain)\n",
    "\n",
    "                # Backpropogation\n",
    "                \n",
    "                self.optim.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optim.step()\n",
    "                \n",
    "                # For averaging and reporting later\n",
    "                running_loss += train_loss\n",
    "                \n",
    "                # convert predictions to numpy\n",
    "                train_predictions = torch.argmax(pred, 1).detach().cpu().numpy()\n",
    "                train_labels = ytrain.detach().cpu().numpy()\n",
    "                \n",
    "                # append to stats\n",
    "                all_train_labels += [train_predictions]\n",
    "                all_train_preds += [train_labels]\n",
    "\n",
    "                # show the current loss to the progress bar\n",
    "                train_pbar_desc = f'loss: {train_loss.item():.4f}'\n",
    "                train_prog_bar.set_description(desc=train_pbar_desc)\n",
    "                \n",
    "                # average the running loss over all batches and return\n",
    "                train_running_loss = running_loss / len(self.train)\n",
    "                print(f\"Final Training Loss: {train_running_loss:.4f}\")\n",
    "                \n",
    "                # free memory\n",
    "                del all_train_labels, all_train_preds, train_predictions, train_labels, xtrain, ytrain, pred\n",
    "                # free up cache\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                return(train_running_loss)\n",
    "        \n",
    "\n",
    "    def valid_one_cycle(self):\n",
    "        \"\"\"\n",
    "        Run one epoch of prediction.\n",
    "        \"\"\"\n",
    "            \n",
    "        # model eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        # progress bar\n",
    "        valid_prog_bar = tqdm(self.valid, total=len(self.train))\n",
    "        \n",
    "        # stats\n",
    "        all_valid_labels = []\n",
    "        all_valid_preds = []\n",
    "        running_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for xval, yval in valid_prog_bar:\n",
    "                # send to devices\n",
    "                xval = xval.to(self.device).float()\n",
    "                yval = yval.to(self.device).float()\n",
    "\n",
    "                # get predictions\n",
    "                pred = model(xval).float()\n",
    "\n",
    "                # training\n",
    "                val_loss = self.val_loss_fn(pred, yval)\n",
    "    \n",
    "                # For averaging and reporting later\n",
    "                running_loss += val_loss.item()\n",
    "                \n",
    "                # convert predictions to numpy\n",
    "                val_pred = torch.argmax(pred, 1).detach().cpu().numpy()\n",
    "                val_label = yval.detach().cpu().numpy()\n",
    "                \n",
    "                # append to stats\n",
    "                all_valid_labels += [val_label]\n",
    "                all_valid_preds += [val_pred]\n",
    "\n",
    "                # show the current loss to the progress bar\n",
    "                valid_pbar_desc = f'loss: {val_loss.item():.4f}'\n",
    "                valid_prog_bar.set_description(desc=valid_pbar_desc)\n",
    "                \n",
    "                # average the running loss over all batches and return\n",
    "                final_loss_val = running_loss / len(self.train)\n",
    "                \n",
    "                # Get Validation Accuracy\n",
    "                all_valid_labels = np.concatenate(all_valid_labels)\n",
    "                all_valid_preds = np.concatenate(all_valid_preds)\n",
    "                \n",
    "                \n",
    "                \n",
    "                print(f\"Final Validation Loss: {final_loss_val:.4f}\")                \n",
    "                \n",
    "                # Free up memory\n",
    "                del all_valid_labels, all_valid_preds, val_label, val_pred, xval, yval, pred\n",
    "                # free cache\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                return(final_loss_val, model)            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f9d19",
   "metadata": {},
   "source": [
    "# Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac98bb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training on 5067 samples (80%) and validation on 1267 (20%) samples\n",
      "\n",
      "[INFO] GPU not found. Using CPU: i386\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.8209:   0%|          | 0/159 [00:00<?, ?it/s]\n",
      "  0%|          | 0/159 [00:00<?, ?it/s]\u001b[A\n",
      "loss: 0.8196:   0%|          | 0/159 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model: NN\n",
      "-------------------- EPOCH: 1/1 --------------------\n",
      "Final Training Loss: 0.0052\n",
      "Final Validation Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Cycle\n",
    "nb_training_samples = int(Config.train_pcent * train.id.shape[0])\n",
    "train_data = train[:nb_training_samples]\n",
    "valid_data = train[nb_training_samples:]\n",
    "\n",
    "print(f\"[INFO] Training on {train_data.shape[0]} samples ({int(Config.train_pcent*100)}%) and validation on {valid_data.shape[0]} ({ceil(abs(1 - Config.train_pcent) * 100)}%) samples\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "        DEVICE = torch.device('cuda:0')\n",
    "else:\n",
    "    print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n",
    "    DEVICE = torch.device('cpu')\n",
    "        \n",
    "\n",
    "# Make Training and Validation Datasets\n",
    "training_set = SIIM(\n",
    "    df=train_data\n",
    ")\n",
    "\n",
    "validation_set = SIIM(\n",
    "    df=valid_data\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    training_set,\n",
    "    batch_size=Config.TRAIN_BS,\n",
    "    shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    validation_set,\n",
    "    batch_size=Config.VALID_BS,\n",
    "    shuffle=False)\n",
    "\n",
    "if \"NN\" in Config.model_name in Config.model_name:        \n",
    "    model = NN().to(DEVICE)\n",
    "    \n",
    "else:\n",
    "    raise RuntimeError(\"Must specify a valid model type to train.\")\n",
    "\n",
    "print(f\"Training Model: {Config.model_name}\")\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "loss_fn_train = nn.BCELoss()\n",
    "loss_fn_val = nn.BCELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    train_dataloader=train_loader,\n",
    "    valid_dataloader=valid_loader,\n",
    "    model=model,\n",
    "    optimiser=optim,\n",
    "    loss_fn=loss_fn_train,\n",
    "    val_loss_fn=loss_fn_val,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "train_losses_eff = []\n",
    "valid_losses_eff = []\n",
    "\n",
    "for epoch in range(Config.NB_EPOCHS):\n",
    "    print(f\"{'-'*20} EPOCH: {epoch+1}/{Config.NB_EPOCHS} {'-'*20}\")\n",
    "\n",
    "    # Run one training epoch\n",
    "    current_train_loss = trainer.train_one_cycle()\n",
    "    train_losses_eff.append(current_train_loss)\n",
    "\n",
    "    # Run one validation epoch\n",
    "    current_val_loss, op_model = trainer.valid_one_cycle()\n",
    "    valid_losses_eff.append(current_val_loss)\n",
    "\n",
    "    # Empty CUDA cache\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
