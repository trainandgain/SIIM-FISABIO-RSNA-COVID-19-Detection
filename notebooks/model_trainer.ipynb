{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "671c63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import platform\n",
    "\n",
    "\n",
    "# vis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adff9c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "train = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a41bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_pcent = 0.8\n",
    "    TRAIN_BS = 32\n",
    "    VALID_BS = 16\n",
    "    NB_EPOCHS = 1\n",
    "    model_name = 'NN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9e544",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70a7d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIIM(Dataset):\n",
    "    def __init__(self, df, is_train=True, augments=None):\n",
    "        super().__init__()\n",
    "        # random sample data\n",
    "        self.df = df.sample(frac=1).reset_index(drop=True)\n",
    "        # training or validation\n",
    "        self.is_train = is_train\n",
    "        # augmentations\n",
    "        self.augments = augments\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_image(image_path):\n",
    "        return ''\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # retrieve image\n",
    "        image_id = self.df['StudyInstanceUID'].values[idx]\n",
    "        image_path = '' # self.df['path'].values[idx]\n",
    "        # get image (obviously change in real implementation)\n",
    "        image = self.get_image(image_path)\n",
    "        \n",
    "        # Augments\n",
    "        if self.augments:\n",
    "            image = self.augments(image=image)\n",
    "        else:\n",
    "            image = torch.tensor(image)\n",
    "            \n",
    "        # if train\n",
    "        if self.is_train:\n",
    "            label = self.df[self.df['StudyInstanceUID'] == image_id].values.tolist()[0][4:-1]\n",
    "            return image, torch.tensor(label)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.df.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c1f70",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Fake model function that should output a value of 1 for either:\n",
    "\n",
    "<code>'negative', 'typical', 'indeterminate', 'atypical'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bb55fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(NN, self).__init__()\n",
    "        # model spec\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # batch size\n",
    "        batch_size = X.shape[0]\n",
    "        # create fake data\n",
    "        rand = torch.randn([batch_size, 4])\n",
    "        return self.out(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f038ff59",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abf2b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, train_dataloader, valid_dataloader, model,\n",
    "                optimiser, loss_fn, val_loss_fn, device='cpu'):\n",
    "        \"\"\"\n",
    "        Constructor for Trainer class\n",
    "        \"\"\"\n",
    "        self.train = train_dataloader\n",
    "        self.valid = valid_dataloader\n",
    "        self.model = model\n",
    "        self.optim = optimiser\n",
    "        self.loss_fn = loss_fn\n",
    "        self.val_loss_fn = val_loss_fn\n",
    "        self.device = device\n",
    "        \n",
    "    def train_one_cycle(self):\n",
    "        \"\"\"\n",
    "        Run one epoch of training, backpropogation and optimisation.\n",
    "        \"\"\"\n",
    "            \n",
    "        # model train mode\n",
    "        model.train()\n",
    "        \n",
    "        # progress bar\n",
    "        train_prog_bar = tqdm(self.train, total=len(self.train))\n",
    "        \n",
    "        # stats\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "        running_loss = 0\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            for xtrain, ytrain in train_prog_bar:\n",
    "                # send to devices\n",
    "                xtrain = xtrain.to(self.device).float()\n",
    "                ytrain = ytrain.to(self.device).float()\n",
    "\n",
    "                # get predictions\n",
    "                pred = model(xtrain)\n",
    "\n",
    "                # training\n",
    "                train_loss = self.loss_fn(pred, ytrain)\n",
    "\n",
    "                # Backpropogation\n",
    "                if self.optimiser:\n",
    "                    self.optimiser.zero_grad()\n",
    "                    self.optimiser.step()\n",
    "                train_loss.backward()\n",
    "                # For averaging and reporting later\n",
    "                running_loss += train_loss\n",
    "                \n",
    "                # convert predictions to numpy\n",
    "                train_predictions = torch.argmax(pred, 1).detach().cpu().numpy()\n",
    "                train_labels = ytrain.detach().cpu().numpy()\n",
    "                \n",
    "                # append to stats\n",
    "                all_train_labels += [train_predictions]\n",
    "                all_train_preds += [train_labels]\n",
    "\n",
    "                # show the current loss to the progress bar\n",
    "                train_pbar_desc = f'loss: {train_loss.item():.4f}'\n",
    "                train_prog_bar.set_description(desc=train_pbar_desc)\n",
    "                \n",
    "                # average the running loss over all batches and return\n",
    "                train_running_loss = running_loss / len(self.train)\n",
    "                print(f\"Final Training Loss: {train_running_loss:.4f}\")\n",
    "                \n",
    "                # free memory\n",
    "                del all_train_labels, all_train_preds, train_predictions, train_labels, xtrain, ytrain, pred\n",
    "                # free up cache\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                return(train_running_loss)\n",
    "        \n",
    "\n",
    "    def valid_one_cycle(self):\n",
    "        \"\"\"\n",
    "        Run one epoch of prediction.\n",
    "        \"\"\"\n",
    "            \n",
    "        # model eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        # progress bar\n",
    "        valid_prog_bar = tqdm(self.valid, total=len(self.train))\n",
    "        \n",
    "        # stats\n",
    "        all_valid_labels = []\n",
    "        all_valid_preds = []\n",
    "        running_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for xtrain, ytrain in valid_prog_bar:\n",
    "                # send to devices\n",
    "                xtrain = xtrain.to(self.device).float()\n",
    "                ytrain = ytrain.to(self.device).float()\n",
    "\n",
    "                # get predictions\n",
    "                pred = model(xtrain)\n",
    "\n",
    "                # training\n",
    "                val_loss = self.val_loss_fn(pred, ytrain)\n",
    "\n",
    "                # Backpropogation\n",
    "                if self.optimiser:\n",
    "                    self.optimiser.zero_grad()\n",
    "                    self.optimiser.step()\n",
    "                    \n",
    "                train_loss.backward()\n",
    "    \n",
    "\n",
    "                # For averaging and reporting later\n",
    "                running_loss += val_loss.item()\n",
    "                \n",
    "                # convert predictions to numpy\n",
    "                val_pred = torch.argmax(pred, 1).detach().cpu().numpy()\n",
    "                val_label = ytrain.detach().cpu().numpy()\n",
    "                \n",
    "                # append to stats\n",
    "                all_valid_labels += [val_label]\n",
    "                all_valid_preds += [val_pred]\n",
    "\n",
    "                # show the current loss to the progress bar\n",
    "                valid_pbar_desc = f'loss: {val_loss.item():.4f}'\n",
    "                valid_prog_bar.set_description(desc=valid_pbar_desc)\n",
    "                \n",
    "                # average the running loss over all batches and return\n",
    "                final_loss_val = running_loss / len(self.train)\n",
    "                \n",
    "                # Get Validation Accuracy\n",
    "                all_valid_labels = np.concatenate(all_valid_labels)\n",
    "                all_valid_preds = np.concatenate(all_valid_preds)\n",
    "                \n",
    "                \n",
    "                \n",
    "                print(f\"Final Training Loss: {train_running_loss:.4f}\")\n",
    "                \n",
    "                # Free up memory\n",
    "                del all_valid_labels, all_valid_preds, val_label, val_pred, xval, yval, pred\n",
    "                # free cache\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                return(final_loss_val, model)            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f9d19",
   "metadata": {},
   "source": [
    "# Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac98bb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training on 5067 samples (80%) and validation on 1267 (20%) samples\n",
      "\n",
      "[INFO] GPU not found. Using CPU: i386\n",
      "\n",
      "Training Model: NN\n",
      "-------------------- EPOCH: 1/1 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/159 [00:35<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-228b3979d329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Run one training epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcurrent_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mtrain_losses_eff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-0dc18b5278b8>\u001b[0m in \u001b[0;36mtrain_one_cycle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_prog_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;31m# send to devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/ml/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Cycle\n",
    "nb_training_samples = int(Config.train_pcent * train.id.shape[0])\n",
    "train_data = train[:nb_training_samples]\n",
    "valid_data = train[nb_training_samples:]\n",
    "\n",
    "print(f\"[INFO] Training on {train_data.shape[0]} samples ({int(Config.train_pcent*100)}%) and validation on {valid_data.shape[0]} ({ceil(abs(1 - Config.train_pcent) * 100)}%) samples\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "        DEVICE = torch.device('cuda:0')\n",
    "else:\n",
    "    print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n",
    "    DEVICE = torch.device('cpu')\n",
    "        \n",
    "\n",
    "# Make Training and Validation Datasets\n",
    "training_set = SIIM(\n",
    "    df=train_data\n",
    ")\n",
    "\n",
    "validation_set = SIIM(\n",
    "    df=valid_data\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    training_set,\n",
    "    batch_size=Config.TRAIN_BS,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    validation_set,\n",
    "    batch_size=Config.VALID_BS,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "if \"NN\" in Config.model_name in Config.model_name:        \n",
    "    model = NN().to(DEVICE)\n",
    "    \n",
    "else:\n",
    "    raise RuntimeError(\"Must specify a valid model type to train.\")\n",
    "\n",
    "print(f\"Training Model: {Config.model_name}\")\n",
    "\n",
    "optim = None # torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "loss_fn_train = nn.BCELoss()\n",
    "loss_fn_val = nn.BCELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    train_dataloader=train_loader,\n",
    "    valid_dataloader=valid_loader,\n",
    "    model=model,\n",
    "    optimiser=optim,\n",
    "    loss_fn=loss_fn_train,\n",
    "    val_loss_fn=loss_fn_val,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "train_losses_eff = []\n",
    "valid_losses_eff = []\n",
    "\n",
    "for epoch in range(Config.NB_EPOCHS):\n",
    "    print(f\"{'-'*20} EPOCH: {epoch+1}/{Config.NB_EPOCHS} {'-'*20}\")\n",
    "\n",
    "    # Run one training epoch\n",
    "    current_train_loss = trainer.train_one_cycle()\n",
    "    train_losses_eff.append(current_train_loss)\n",
    "\n",
    "    # Run one validation epoch\n",
    "    current_val_loss, op_model = trainer.valid_one_cycle()\n",
    "    valid_losses_eff.append(current_val_loss)\n",
    "\n",
    "    # Empty CUDA cache\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
