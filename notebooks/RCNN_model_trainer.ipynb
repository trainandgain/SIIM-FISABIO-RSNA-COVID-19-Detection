{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comparable-monroe",
   "metadata": {},
   "source": [
    "# FasterRCNN\n",
    "\n",
    "I am little bit confused about repeated instances of boxes. By exploding the dataset into multiple instance~s of the same ID's we are viewing every image N times, where N is the number of boxes (Opacity Count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671c63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import platform\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import  FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import glob\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# vis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "from math import ceil\n",
    "import cv2\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adff9c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "train = pd.read_csv('../input/train_exploded_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stable-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_pcent = 0.8\n",
    "    TRAIN_BS = 4\n",
    "    VALID_BS = 4\n",
    "    NB_EPOCHS = 3\n",
    "    model_name = 'FastRCNN'\n",
    "    reshape_size = (400, 400)\n",
    "    num_classes = 4\n",
    "    seed = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-generator",
   "metadata": {},
   "source": [
    "# Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automated-pakistan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  integer_label\n",
      "0     0                 334\n",
      "      1                1160\n",
      "      2                 286\n",
      "      3                 121\n",
      "1     0                 334\n",
      "      1                1160\n",
      "      2                 286\n",
      "      3                 121\n",
      "2     0                 334\n",
      "      1                1160\n",
      "      2                 286\n",
      "      3                 121\n",
      "3     0                 334\n",
      "      1                1160\n",
      "      2                 286\n",
      "      3                 121\n",
      "4     0                 333\n",
      "      1                1159\n",
      "      2                 286\n",
      "      3                 122\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split into folds\n",
    "df_folds = train.copy()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=Config.seed)\n",
    "for n, (train_index, val_index) in enumerate(skf.split(X=df_folds.index, y=df_folds.integer_label)):\n",
    "    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = int(n)\n",
    "df_folds['fold'] = df_folds['fold'].astype(int)\n",
    "print(df_folds.groupby(['fold', df_folds.integer_label]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "average-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['000a312787f2', '000a312787f2', '0012ff7358bc', '0012ff7358bc',\n",
       "       '001398f4ff4f', '001bd15d1891', '001bd15d1891', '0022227f5adf',\n",
       "       '002e9b2128d0', '002e9b2128d0',\n",
       "       ...\n",
       "       'ff01229b525c', 'ff03d1d41968', 'ff0743bee789', 'ff4cd60f14b7',\n",
       "       'ff6ee6ae167b', 'ff7659762b75', 'ff9f10a24c27', 'ffa9fef3c7bf',\n",
       "       'ffcc6edd9445', 'ffd91a2c4ca0'],\n",
       "      dtype='object', name='id', length=9504)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds.set_index('id').index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-index",
   "metadata": {},
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIIM(Dataset):\n",
    "    def __init__(self, image_ids, df, is_train=True, augments=None, \n",
    "                 reshape_size=Config.reshape_size):\n",
    "        super().__init__()\n",
    "        # image_ids\n",
    "        self.image_ids = image_ids\n",
    "        # random sample data\n",
    "        self.df = df\n",
    "        # training or validation\n",
    "        self.is_train = is_train\n",
    "        # augmentations\n",
    "        self.augments = augments\n",
    "        # reshape size\n",
    "        self.reshape_size = reshape_size\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return(len(self.df.shape[0]))\n",
    "    \n",
    "    @staticmethod\n",
    "    def dicom2array(path: str, voi_lut=True, fix_monochrome=True):\n",
    "        dicom = pydicom.read_file(path)\n",
    "        # VOI LUT (if available by DICOM device) is used to\n",
    "        # transform raw DICOM data to \"human-friendly\" view\n",
    "        if voi_lut:\n",
    "            data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "        else:\n",
    "            data = dicom.pixel_array\n",
    "        # depending on this value, X-ray may look inverted - fix that:\n",
    "        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            data = np.amax(data) - data\n",
    "        data = data - np.min(data)\n",
    "        data = data / np.max(data)\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data\n",
    "    \n",
    "    def load_bbox_labels(idx: int):\n",
    "        return(data)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        # retrieve idx data\n",
    "        image_id = self.image_ids[idx]\n",
    "        # get path\n",
    "        image_path = self.df['path'].values[idx]\n",
    "        # get image\n",
    "        image = self.dicom2array(image_path)\n",
    "        # get boxes and labels\n",
    "        boxes, labels = self.load_bbox_labels(idx)\n",
    "        \n",
    "        \n",
    "        # Augments\n",
    "        if self.augments:\n",
    "            image = self.augments(image=image)\n",
    "        else:\n",
    "            image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "            image = torch.tensor(image)  \n",
    "        # if train\n",
    "        if self.is_train:\n",
    "            label = self.df[self.df['StudyInstanceUID'] == image_id].values.tolist()[0][4:-2]\n",
    "            return image, torch.tensor(label)\n",
    "\n",
    "        return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell]",
   "language": "python",
   "name": "conda-env-cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
